{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Explore and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "wvs = pd.read_csv(\"wvs.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>MN_228S8</th>\n",
       "      <th>MN_229A</th>\n",
       "      <th>MN_230A</th>\n",
       "      <th>MN_233A</th>\n",
       "      <th>MN_237B1</th>\n",
       "      <th>MN_249A1</th>\n",
       "      <th>MN_249A3</th>\n",
       "      <th>I_RELIGBEL</th>\n",
       "      <th>I_NORM1</th>\n",
       "      <th>I_VOICE1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>54926</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55073</td>\n",
       "      <td>275</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13911</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50155</td>\n",
       "      <td>528</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16125</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23553</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        V2  V4  V5  V6  V7  V8  V9  V10  V11  V12  ...  MN_228S8  MN_229A  \\\n",
       "54926  275   1   2   2   3   1   1    1    2    2  ...        -4       -4   \n",
       "55073  275   2   2   3   2   2   1    2    3    2  ...        -4       -4   \n",
       "13911  156   1   1   1   4   1   4    1    1    1  ...        -4       -4   \n",
       "50155  528   1   1   2   2   2   3    1    2    1  ...        -4       -4   \n",
       "16125  218   1   1   1   3   1   2    1    1    2  ...        -4       -4   \n",
       "23553  288   1   2   1   2   1   1    2    1    1  ...        -4       -4   \n",
       "\n",
       "       MN_230A  MN_233A  MN_237B1  MN_249A1  MN_249A3  I_RELIGBEL  I_NORM1  \\\n",
       "54926       -4       -4        -4        -4        -4         0.0      1.0   \n",
       "55073       -4       -4        -4        -4        -4         0.0      1.0   \n",
       "13911       -4       -4        -4        -4        -4         1.0      1.0   \n",
       "50155       -4       -4        -4        -4        -4         1.0      0.0   \n",
       "16125       -4       -4        -4        -4        -4         0.0      1.0   \n",
       "23553       -4       -4        -4        -4        -4         0.0      0.0   \n",
       "\n",
       "       I_VOICE1  \n",
       "54926      0.00  \n",
       "55073      0.00  \n",
       "13911      0.00  \n",
       "50155      0.66  \n",
       "16125      0.00  \n",
       "23553      0.66  \n",
       "\n",
       "[6 rows x 328 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the data\n",
    "wvs.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90350, 328)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check out the dimensions\n",
    "wvs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean V23 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take all cases where there are no missing answers survey wise\n",
    "wvs_clean = wvs[wvs.V23 > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89771, 328)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all NA's\n",
    "wvs_clean = wvs_clean[~wvs_clean.V23.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89771, 328)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a plot of different answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>18213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>11331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>9264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Frequency\n",
       "0      8      18213\n",
       "1      7      15493\n",
       "2     10      11928\n",
       "3      5      11331\n",
       "4      6      10666\n",
       "5      9       9264\n",
       "6      4       4600\n",
       "7      3       3463\n",
       "8      1       2828\n",
       "9      2       1985"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the value counts for V23\n",
    "wvs_clean.V23.value_counts().reset_index(name=\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1250f7110>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the frequencies\n",
    "sns.countplot(x=\"V23\",data=wvs_clean,palette=\"coolwarm\",order = wvs_clean['V23'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a variable to denote cases where satisfaction rating higher than 6\n",
    "wvs_clean['satisfied'] = wvs_clean.V23.apply(lambda x: 1 if x>5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    73.034722\n",
       "0    26.965278\n",
       "Name: satisfied, dtype: float64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View relative frequencies\n",
    "wvs_clean.satisfied.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above response 73% of the respondents are at a satisfaction level greater than 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Create the design matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select more than 100 variables and create outcome variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset based on selected 100+ variables\n",
    "wvs_100 = wvs_clean[['V2', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11','V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V49', 'V55', 'V57', 'V58', 'V59', 'V70', 'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V102', 'V103', 'V104', 'V105', 'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113', 'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121', 'V122', 'V123', 'V124', 'V126', 'V145', 'V146', 'V147', 'V148', 'V149', 'V152', 'V170', 'V171', 'V172', 'V173' , 'V174', 'V175', 'V179', 'V180', 'V181', 'V182', 'V183', 'V184', 'V185', 'V186', 'V188', 'V189', 'V190', 'V191', 'V211', 'V212', 'V213', 'V214', 'V216', 'V229', 'V230', 'V231', 'V232', 'V233', 'V234', 'V235', 'V236', 'V237', 'V238', 'V239', 'V240', 'V243', 'V245', 'V246', 'V248', 'V253', 'V255']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89771, 108)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs_100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hshetty/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "#Drop NA's for selected variables\n",
    "wvs_100.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V23</th>\n",
       "      <th>...</th>\n",
       "      <th>V237</th>\n",
       "      <th>V238</th>\n",
       "      <th>V239</th>\n",
       "      <th>V240</th>\n",
       "      <th>V243</th>\n",
       "      <th>V245</th>\n",
       "      <th>V246</th>\n",
       "      <th>V248</th>\n",
       "      <th>V253</th>\n",
       "      <th>V255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V2  V4  V5  V6  V7  V8  V9  V10  V11  V23  ...  V237  V238  V239  V240  \\\n",
       "0  12   1   1   1  -2   1   1    2    1    8  ...     1     4     5     1   \n",
       "1  12   1   2   3   4   2   2    2    2    5  ...     2     3     6     2   \n",
       "2  12   1   3   2   4   2   1    2    2    4  ...     1     4     6     2   \n",
       "3  12   1   1   3   4   3   1    2    1    8  ...     4     4     5     2   \n",
       "4  12   1   1   1   2   1   1    1    3    8  ...     2     3     7     2   \n",
       "\n",
       "   V243  V245  V246  V248  V253  V255  \n",
       "0     2     1     1   7.0     1     1  \n",
       "1     2     1     1   7.0     1     1  \n",
       "2     2     1     1   5.0     1     1  \n",
       "3     2     1     1   6.0     1     1  \n",
       "4     2     1     1   3.0     1     1  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89770, 108)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs_100.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hshetty/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "#Remove all cases where we have missing answers\n",
    "for column in wvs_100.columns:\n",
    "    wvs_100.drop(wvs_100[wvs_100[column] < 0].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create outcome variable\n",
    "Y = wvs_100.V23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V2</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V23</th>\n",
       "      <th>...</th>\n",
       "      <th>V237</th>\n",
       "      <th>V238</th>\n",
       "      <th>V239</th>\n",
       "      <th>V240</th>\n",
       "      <th>V243</th>\n",
       "      <th>V245</th>\n",
       "      <th>V246</th>\n",
       "      <th>V248</th>\n",
       "      <th>V253</th>\n",
       "      <th>V255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    V2  V4  V5  V6  V7  V8  V9  V10  V11  V23  ...  V237  V238  V239  V240  \\\n",
       "4   12   1   1   1   2   1   1    1    3    8  ...     2     3     7     2   \n",
       "14  12   1   2   3   4   4   1    2    3    4  ...     4     5     4     1   \n",
       "31  12   1   4   1   4   1   1    2    2   10  ...     1     3     4     2   \n",
       "55  12   1   1   2   4   2   1    3    2    5  ...     4     4     4     1   \n",
       "57  12   1   1   1   2   1   1    3    3    1  ...     2     4     5     1   \n",
       "\n",
       "    V243  V245  V246  V248  V253  V255  \n",
       "4      2     1     1   3.0     1     1  \n",
       "14     2     1     1   3.0     1     1  \n",
       "31     2     1     1   3.0     1     1  \n",
       "55     2     1     1   5.0     1     1  \n",
       "57     2     1     1   9.0     1     1  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvs_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13481,)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical variables into dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables that are categorical are - V2, V24, V25, V26, V27, V28, V29, V30, V31, V32, V33, V34, V35, V57, V147, V148, V149, V179, V180, V230, V234, V235, V236, V237, V240, V243, V245, V246 AND V255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "cat_cols = ['V2', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30', 'V31', 'V32', 'V33', 'V34', 'V35', 'V57', 'V147', 'V148', 'V149', 'V179', 'V180', 'V230', 'V234', 'V235', 'V236', 'V237', 'V240', 'V243', 'V245', 'V246' , 'V255']\n",
    "\n",
    "wvs_100 = pd.get_dummies(data=wvs_100, columns=cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Condition Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition numbers\n",
      "V4 , 1 columns, k= 1.0\n",
      "V5 , 2 columns, k= 4.817556146145612\n",
      "V6 , 3 columns, k= 6.83268891471901\n",
      "V7 , 4 columns, k= 9.653095272764018\n",
      "V8 , 5 columns, k= 11.074676190580623\n",
      "V9 , 6 columns, k= 12.0670254781654\n",
      "V10 , 7 columns, k= 13.409629892752902\n",
      "V11 , 8 columns, k= 14.606965351142664\n",
      "V23 , 9 columns, k= 25.747766739215397\n",
      "V49 , 10 columns, k= 26.3604367037649\n",
      "V55 , 11 columns, k= 34.58902431845327\n",
      "V58 , 12 columns, k= 35.04952350813847\n",
      "V59 , 13 columns, k= 39.6059568541214\n",
      "V70 , 14 columns, k= 40.335625081605166\n",
      "V71 , 15 columns, k= 41.81030621839575\n",
      "V72 , 16 columns, k= 42.547009637399164\n",
      "V73 , 17 columns, k= 43.57424836488091\n",
      "V74 , 18 columns, k= 44.12376785198366\n",
      "V75 , 19 columns, k= 44.870241205173684\n",
      "V76 , 20 columns, k= 46.06763641761684\n",
      "V77 , 21 columns, k= 46.679824316824444\n",
      "V78 , 22 columns, k= 47.301415883607504\n",
      "V79 , 23 columns, k= 47.91650871050504\n",
      "V102 , 24 columns, k= 49.908537251919874\n",
      "V103 , 25 columns, k= 50.472447682625365\n",
      "V104 , 26 columns, k= 50.960987932986555\n",
      "V105 , 27 columns, k= 51.950902796475845\n",
      "V106 , 28 columns, k= 52.67925826803876\n",
      "V107 , 29 columns, k= 53.45301622004948\n",
      "V108 , 30 columns, k= 53.80323410370372\n",
      "V109 , 31 columns, k= 54.29736302005988\n",
      "V110 , 32 columns, k= 54.91463338198377\n",
      "V111 , 33 columns, k= 55.45992813215251\n",
      "V112 , 34 columns, k= 56.10396652735488\n",
      "V113 , 35 columns, k= 56.685116400804404\n",
      "V114 , 36 columns, k= 57.234365253267896\n",
      "V115 , 37 columns, k= 57.85189552101607\n",
      "V116 , 38 columns, k= 58.6010085197613\n",
      "V117 , 39 columns, k= 59.23017666849541\n",
      "V118 , 40 columns, k= 59.789530770785746\n",
      "V119 , 41 columns, k= 60.1567979523608\n",
      "V120 , 42 columns, k= 60.62736181273677\n",
      "V121 , 43 columns, k= 61.06937294330948\n",
      "V122 , 44 columns, k= 61.50216592708161\n",
      "V123 , 45 columns, k= 61.93803351076598\n",
      "V124 , 46 columns, k= 62.36040399451041\n",
      "V126 , 47 columns, k= 62.86079921636794\n",
      "V145 , 48 columns, k= 63.7569986504596\n",
      "V146 , 49 columns, k= 64.47334133969187\n",
      "V152 , 50 columns, k= 70.03202925806276\n",
      "V170 , 51 columns, k= 70.40979084787399\n",
      "V171 , 52 columns, k= 71.21207917127933\n",
      "V172 , 53 columns, k= 71.74599968245289\n",
      "V173 , 54 columns, k= 72.54290029239559\n",
      "V174 , 55 columns, k= 73.38357267798705\n",
      "V175 , 56 columns, k= 74.07091747381777\n",
      "V181 , 57 columns, k= 74.2932484314961\n",
      "V182 , 58 columns, k= 74.60947389336428\n",
      "V183 , 59 columns, k= 74.85914009457171\n",
      "V184 , 60 columns, k= 75.08800966743716\n",
      "V185 , 61 columns, k= 75.34118569827048\n",
      "V186 , 62 columns, k= 75.72327071723629\n",
      "V188 , 63 columns, k= 76.48235015299242\n",
      "V189 , 64 columns, k= 77.16010005049486\n",
      "V190 , 65 columns, k= 77.81299726791399\n",
      "V191 , 66 columns, k= 78.35674521884935\n",
      "V211 , 67 columns, k= 78.55039619217514\n",
      "V212 , 68 columns, k= 78.77681911536563\n",
      "V213 , 69 columns, k= 79.04154085891227\n",
      "V214 , 70 columns, k= 79.2393178452889\n",
      "V216 , 71 columns, k= 79.49830389178207\n",
      "V229 , 72 columns, k= 80.16604906276021\n",
      "V231 , 73 columns, k= 81.81027283468934\n",
      "V232 , 74 columns, k= 83.27453280865878\n",
      "V233 , 75 columns, k= 86.05924833930153\n",
      "V238 , 76 columns, k= 86.73349947543262\n",
      "V239 , 77 columns, k= 88.23190347117698\n",
      "V248 , 78 columns, k= 90.18615229762722\n",
      "V253 , 79 columns, k= 91.42771688582403\n",
      "V2_31 , 80 columns, k= 176.52414068312356\n",
      "V2_51 , 81 columns, k= 226.88132318788874\n",
      "V2_76 , 82 columns, k= 227.05750074451046\n",
      "V2_112 , 83 columns, k= 282.6405376271572\n",
      "V2_152 , 84 columns, k= 369.5914378645369\n",
      "V2_196 , 85 columns, k= 369.8017560905653\n",
      "V2_218 , 86 columns, k= 370.3719516160384\n",
      "V2_233 , 87 columns, k= 370.5426806709554\n",
      "V2_268 , 88 columns, k= 370.59020100231396\n",
      "V2_288 , 89 columns, k= 370.593011212691\n",
      "V2_356 , 90 columns, k= 370.73669351924036\n",
      "V2_368 , 91 columns, k= 402.15065782042205\n",
      "V2_398 , 92 columns, k= 402.30706633652284\n",
      "V2_400 , 93 columns, k= 414.0011359139414\n",
      "V2_417 , 94 columns, k= 414.22564894302036\n",
      "V2_422 , 95 columns, k= 922.0239371027244\n",
      "V2_434 , 96 columns, k= 922.2581600383826\n",
      "V2_458 , 97 columns, k= 922.3550077681033\n",
      "V2_484 , 98 columns, k= 922.5080253560504\n",
      "V2_528 , 99 columns, k= 922.6129496711092\n",
      "V2_566 , 100 columns, k= 922.7762943962365\n",
      "V2_604 , 101 columns, k= 922.9386109641431\n",
      "V2_608 , 102 columns, k= 923.2553617620574\n",
      "V2_616 , 103 columns, k= 923.4106171634335\n",
      "V2_642 , 104 columns, k= 924.0780336766568\n",
      "V2_643 , 105 columns, k= 924.24186135033\n",
      "V2_646 , 106 columns, k= 924.8317605018956\n",
      "V2_710 , 107 columns, k= 928.0560500017642\n",
      "V2_716 , 108 columns, k= 943.7498720050412\n",
      "V2_752 , 109 columns, k= 961.7304293076721\n",
      "V2_764 , 110 columns, k= 995.6972177492651\n",
      "V2_804 , 111 columns, k= 1332.171208749852\n",
      "V2_858 , 112 columns, k= 1847.4985876934643\n",
      "V24_2 , 113 columns, k= 1853.1075141068422\n",
      "V25_1 , 114 columns, k= 1854.5165965474196\n",
      "V25_2 , 115 columns, k= 1874.672709034904\n",
      "V26_1 , 116 columns, k= 1875.7165000881355\n",
      "V26_2 , 117 columns, k= 1880.2498492200652\n",
      "V27_1 , 118 columns, k= 1880.3085776241032\n",
      "V27_2 , 119 columns, k= 1881.0817355903591\n",
      "V28_1 , 120 columns, k= 1882.0459016647571\n",
      "V28_2 , 121 columns, k= 1883.6146433921915\n",
      "V29_1 , 122 columns, k= 1884.205633030628\n",
      "V29_2 , 123 columns, k= 1887.7068789647599\n",
      "V30_1 , 124 columns, k= 1887.8294138179167\n",
      "V30_2 , 125 columns, k= 1888.1666395563109\n",
      "V31_1 , 126 columns, k= 1888.3280818287715\n",
      "V31_2 , 127 columns, k= 1888.3782391196412\n",
      "V32_1 , 128 columns, k= 1888.4539774682903\n",
      "V32_2 , 129 columns, k= 1888.8100377736348\n",
      "V33_1 , 130 columns, k= 1888.8389858193307\n",
      "V33_2 , 131 columns, k= 1888.9268138826087\n",
      "V34_1 , 132 columns, k= 1888.9959552336586\n",
      "V34_2 , 133 columns, k= 1889.732371060353\n",
      "V35_1 , 134 columns, k= 1889.901425222688\n",
      "V35_2 , 135 columns, k= 1890.3763312650926\n",
      "V57_2 , 136 columns, k= 1891.3099164681703\n",
      "V57_3 , 137 columns, k= 1891.3151405421427\n",
      "V57_4 , 138 columns, k= 1891.4186751737623\n",
      "V57_5 , 139 columns, k= 1891.4269095633765\n",
      "V57_6 , 140 columns, k= 1893.258293524355\n",
      "V147_2 , 141 columns, k= 1893.7053463754298\n",
      "V147_3 , 142 columns, k= 1893.7064079952784\n",
      "V148_2 , 143 columns, k= 1895.722546615856\n",
      "V149_2 , 144 columns, k= 1897.8590028551364\n",
      "V179_5 , 145 columns, k= 1909.1545573548185\n",
      "V180_5 , 146 columns, k= 1915.4180763280788\n",
      "V230_2 , 147 columns, k= 1918.1738107889912\n",
      "V230_3 , 148 columns, k= 1920.819715689841\n",
      "V230_4 , 149 columns, k= 1921.4903654176367\n",
      "V234_2 , 150 columns, k= 1925.5123058603692\n",
      "V235_2 , 151 columns, k= 1926.460684398536\n",
      "V236_2 , 152 columns, k= 1926.7018391789127\n",
      "V237_2 , 153 columns, k= 1928.28103440703\n",
      "V237_3 , 154 columns, k= 1928.7991941347152\n",
      "V237_4 , 155 columns, k= 1933.969463379442\n",
      "V240_2 , 156 columns, k= 1935.9914751367226\n",
      "V243_2 , 157 columns, k= 1952.72811934291\n",
      "V245_2 , 158 columns, k= 1955.7165823090793\n",
      "V246_2 , 159 columns, k= 1955.9093542070882\n",
      "V255_2 , 160 columns, k= 1957.4416166822691\n"
     ]
    }
   ],
   "source": [
    "# print iterative condition number of design matrix\n",
    "wvs_100_mod = pd.DataFrame()\n",
    "ctr = 0\n",
    "print('Condition numbers')\n",
    "\n",
    "for column in wvs_100.columns:\n",
    "    wvs_100_mod[column] = wvs_100[column]\n",
    "    ctr += 1\n",
    "    print(column,',' ,ctr, 'columns, k=',np.linalg.cond(wvs_100_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Do some social science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform OLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    V23   R-squared:                       0.298\n",
      "Model:                            OLS   Adj. R-squared:                  0.298\n",
      "Method:                 Least Squares   F-statistic:                     1911.\n",
      "Date:                Sun, 08 Mar 2020   Prob (F-statistic):               0.00\n",
      "Time:                        14:47:10   Log-Likelihood:                -28269.\n",
      "No. Observations:               13481   AIC:                         5.655e+04\n",
      "Df Residuals:                   13477   BIC:                         5.658e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.4447      0.082     42.139      0.000       3.284       3.605\n",
      "V11           -0.3067      0.020    -14.996      0.000      -0.347      -0.267\n",
      "V59            0.3582      0.007     50.409      0.000       0.344       0.372\n",
      "V55            0.2675      0.008     33.121      0.000       0.252       0.283\n",
      "==============================================================================\n",
      "Omnibus:                      643.268   Durbin-Watson:                   1.659\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1103.854\n",
      "Skew:                          -0.392   Prob(JB):                    2.00e-240\n",
      "Kurtosis:                       4.162   Cond. No.                         49.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# fit using OLS and view results\n",
    "model = smf.ols(formula='V23 ~ V11 + V59 + V55', data=wvs_100_mod).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table shows that the R-squared and the adjusted R-squared are 0.298. This means that the 3 features that we have chose (V11, V55 and V59), explain 29.8% of the variability in the response variable.\n",
    "\n",
    "It is surprising to see that out of the 100+ variables that we have chosen for the model, these 3 features alone account for 30% of the variability. But the low R and adjusted R score also imply that we need to include more variables in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using OLS\n",
    "predictions = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9699084109736726\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "# Calculate RMSE for OLS\n",
    "model_rmse = rmse(Y,predictions)\n",
    "print(model_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Back to ML: Model\n",
    "\n",
    "Now it is time to use all these variables to model satisfaction. Use sklearn.linear_model.LinearRegression\n",
    "here as this is easy to be switched with ridge and lasso, and it takes in the design matrix directly.\n",
    "1. compute the condition number for your design matrix (just a single number, not the stepwise procedure).\n",
    "2. Split the data into training-validation chunks (80-20 or so)\n",
    "3. compute the condition number for your training design matrix (just a single number, not the stepwise procedure).\n",
    "4. Fit a linear regression model where you describe satisfaction with the design matrix X you just created.\n",
    "5. predict and compute RMSE on training data\n",
    "6. predict and compute RMSE on testing data\n",
    "7. repeat the previous with Ridge regression, play a little with different Î±-s. Which Î± gave you the best testing RMSE? (No need for a rigorous analysis, just play a little)\n",
    "8. and repeat with Lasso regression again playing a little with different Î±-s.\n",
    "9. comment your results:\n",
    "    - compare RMSE on testing/training data. What does this suggest in terms of overfitting?\n",
    "    - compare RMSE for OLS, Ridge and Lasso\n",
    "    - compare the resulting RMSE with the small benchmark model you did above\n",
    "\n",
    "If your results are like mine, you see that a) RMSE on both testing-training sets are similar; b) RMSE for\n",
    "OLS, Ridge, Lasso are similar; and c) all these 100 or so extra variables add very little explanatory power\n",
    "to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55785     9\n",
       "57066    10\n",
       "24348     8\n",
       "63988     5\n",
       "51391     7\n",
       "Name: V23, dtype: int64"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outcome variable from input data\n",
    "wvs_100_mod.drop('V23', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute condition numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1879.240738159632"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute condition number on input data\n",
    "np.linalg.cond(wvs_100_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition Number of training design matrix =  1918.269764952689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assign input data to X\n",
    "X = wvs_100_mod\n",
    "\n",
    "#split the data into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print(\"Condition Number of training design matrix = \",np.linalg.cond(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train score =  1.785951303257111\n",
      "RMSE test score =  1.829548814563285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit using linear regression\n",
    "linreg = LinearRegression().fit(X_train, Y_train)\n",
    "train_predict = linreg.predict(X_train)\n",
    "\n",
    "# Calculate RMSE for Linear Reg on train\n",
    "train_rmse = rmse(Y_train, train_predict)\n",
    "print(\"RMSE train score = \", train_rmse)\n",
    "\n",
    "# Calculate RMSE for Linear Reg on test\n",
    "test_predict = linreg.predict(X_test)\n",
    "test_rmse = rmse(Y_test, test_predict)\n",
    "print(\"RMSE test score = \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run ridge regression with different alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha= 0.2\n",
      "RMSE on train =  1.7859966291553586\n",
      "RMSE on test =  1.8292440290201442\n",
      "\n",
      "For alpha= 3\n",
      "RMSE on train =  1.7871075899118918\n",
      "RMSE on test =  1.829036371150448\n",
      "\n",
      "For alpha= 10\n",
      "RMSE on train =  1.7878836295644993\n",
      "RMSE on test =  1.8288092575226558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Create list of different alpha values for ridge\n",
    "alpha_val = [0.2, 3, 10]\n",
    "\n",
    "for val in alpha_val:\n",
    "    # Fit using ridge and different alphas\n",
    "    linreg_ridge = Ridge(alpha=val).fit(X_train, Y_train)\n",
    "    train_ridge_pred = linreg_ridge.predict(X_train)\n",
    "    \n",
    "    # Calculate RMSE for Ridge Reg on train\n",
    "    train_ridge_rmse = rmse(Y_train, train_ridge_pred)\n",
    "    print(\"For alpha=\",val)\n",
    "    print(\"RMSE on train = \", train_ridge_rmse)\n",
    "    \n",
    "    # Calculate RMSE for Ridge Reg on test\n",
    "    test_ridge_pred = linreg_ridge.predict(X_test)\n",
    "    test_ridge_rmse = rmse(Y_test, test_ridge_pred)\n",
    "    print(\"RMSE on test = \", test_ridge_rmse)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run lasso regression with different alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha= 0.1\n",
      "RMSE on train =  1.8720962819611648\n",
      "RMSE on test =  1.8652410474344552\n",
      "\n",
      "For alpha= 0.5\n",
      "RMSE on train =  2.0020169608077634\n",
      "RMSE on test =  2.0011045662998774\n",
      "\n",
      "For alpha= 2\n",
      "RMSE on train =  2.2152040401824227\n",
      "RMSE on test =  2.1978455637437664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create list of different alpha values for lasso\n",
    "lasso_val = [0.1, 0.5, 2]\n",
    "\n",
    "for val in lasso_val:\n",
    "    # Fit using lasso\n",
    "    linreg_lasso = Lasso(alpha=val).fit(X_train, Y_train)\n",
    "    train_lasso_pred = linreg_lasso.predict(X_train)\n",
    "    \n",
    "    # Calculate RMSE for Lasso Reg on train\n",
    "    train_lasso_rmse = rmse(Y_train, train_lasso_pred)\n",
    "    print(\"For alpha=\",val)\n",
    "    print(\"RMSE on train = \", train_lasso_rmse)\n",
    "    \n",
    "    # Calculate RMSE for Lasso Reg on test\n",
    "    test_lasso_pred = linreg_lasso.predict(X_test)\n",
    "    test_lasso_rmse = rmse(Y_test, test_lasso_pred)\n",
    "    print(\"RMSE on test = \", test_lasso_rmse)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compare RMSE on testing/training data. What does this suggest in terms of overfitting?\n",
    "    - The RMSE for the train and testing data in Linear Regression is different which is expected since test error is usually greater than training error. This suggests that the model is slightly overfitting the data. \n",
    "\n",
    "    \n",
    "2. Compare RMSE for OLS, Ridge and Lasso\n",
    "    - OLS RMSE: 1.9699084109736726\n",
    "    - Ridge: Train RMSE is more or less 1.79 whereas Test RMSE is 1.83\n",
    "    - Lasso: Train RMSE for smaller values of alpha is around 1.87 and for higher values is around 2.2. Test RMSE for smaller alpha values is 1.87 whereas for higher values is around 1.86. This could either be because the model generalizes well to the data or it could be because the test set has statistically different properties as compared to training.    \n",
    "    - Based on the above, I would say that the results from ridge were the best followed by OLS and then lasso.\n",
    "\n",
    "\n",
    "3. Compare the resulting RMSE with the small benchmark model you did above\n",
    "    - The benchmarked RMSE was 1.96, which is higher than ridge but lower than the higher alpha values for lasso. This shows that ridge performs the best amongst the three methods. Given that there is not much difference between the benchmarked RMSE and the other methods implies that adding the other 100+ variables, did not improve the model performance much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Overfitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As WVS is a relatively large dataset we cannot easily overfit by adding more variables. But we can go\n",
    "another easy route instead: we take a subsample.\n",
    "1. Create a subsample of your design matrix and the outcome variable. Choose a large-ish sample that overfits. The size depends on which variables do you exactly choose, in my case 2000 obs rarely overfits (it depends on the train-validation split), 1000 typically overfits.\n",
    "2. repeat the steps you did above.\n",
    "3. comment how do OLS, Ridge, Lasso perform on testing/training in case of overfitting.\n",
    "4. comment the condition number of design matrix and overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V49</th>\n",
       "      <th>V55</th>\n",
       "      <th>...</th>\n",
       "      <th>V235_2</th>\n",
       "      <th>V236_2</th>\n",
       "      <th>V237_2</th>\n",
       "      <th>V237_3</th>\n",
       "      <th>V237_4</th>\n",
       "      <th>V240_2</th>\n",
       "      <th>V243_2</th>\n",
       "      <th>V245_2</th>\n",
       "      <th>V246_2</th>\n",
       "      <th>V255_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>42032</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57350</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63862</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46495</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V4  V5  V6  V7  V8  V9  V10  V11  V49  V55  ...  V235_2  V236_2  \\\n",
       "42032   1   1   3   3   1   1    1    1    1    8  ...       0       0   \n",
       "57350   1   2   4   4   1   1    1    1    1   10  ...       0       0   \n",
       "63862   1   1   2   2   1   1    2    3    2    7  ...       0       0   \n",
       "24008   1   1   1   4   1   1    3    2    1    6  ...       1       1   \n",
       "46495   1   2   1   3   1   3    2    2    2    6  ...       1       1   \n",
       "\n",
       "       V237_2  V237_3  V237_4  V240_2  V243_2  V245_2  V246_2  V255_2  \n",
       "42032       1       0       0       0       1       0       0       0  \n",
       "57350       1       0       0       0       1       0       0       0  \n",
       "63862       0       0       0       0       1       0       0       0  \n",
       "24008       0       0       0       1       1       0       0       0  \n",
       "46495       1       0       0       0       1       0       0       0  \n",
       "\n",
       "[5 rows x 159 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a sample of 1000\n",
    "X_sample = wvs_100_mod.sample(n=1000)\n",
    "\n",
    "#Store index values\n",
    "sample_index = list(X_sample.index)\n",
    "X_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42032     7\n",
       "57350    10\n",
       "63862     7\n",
       "24008     7\n",
       "46495     7\n",
       "Name: V23, dtype: int64"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose Y values corresponding to sampled X \n",
    "Y_sample = Y[sample_index]\n",
    "Y_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test\n",
    "X_sample_train, X_sample_test, Y_sample_train, Y_sample_test = train_test_split(X_sample, Y_sample, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression on sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train score =  1.519975815691337\n",
      "RMSE test score =  2.125223279287573\n"
     ]
    }
   ],
   "source": [
    "# Fit using linear\n",
    "linreg = LinearRegression().fit(X_sample_train, Y_sample_train)\n",
    "train_predict = linreg.predict(X_sample_train)\n",
    "\n",
    "# Calculate RMSE for linear Reg on train\n",
    "train_rmse = rmse(Y_sample_train, train_predict)\n",
    "print(\"RMSE train score = \", train_rmse)\n",
    "\n",
    "# Calculate RMSE for linear Reg on test\n",
    "test_predict = linreg.predict(X_sample_test)\n",
    "test_rmse = rmse(Y_sample_test, test_predict)\n",
    "print(\"RMSE test score = \", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression on sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha= 0.2\n",
      "RMSE on train =  1.5203294250739923\n",
      "RMSE on test =  2.1227895574082485\n",
      "\n",
      "For alpha= 3\n",
      "RMSE on train =  1.5280228259253053\n",
      "RMSE on test =  2.08669166466636\n",
      "\n",
      "For alpha= 10\n",
      "RMSE on train =  1.5422927224977836\n",
      "RMSE on test =  2.0590266452203574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create list of different alpha values for ridge\n",
    "alpha_val = [0.2, 3, 10]\n",
    "\n",
    "for val in alpha_val:\n",
    "    #fit using ridge\n",
    "    linreg_ridge = Ridge(alpha=val).fit(X_sample_train, Y_sample_train)\n",
    "    train_ridge_pred = linreg_ridge.predict(X_sample_train)\n",
    "    \n",
    "    # Calculate RMSE for ridge Reg on train\n",
    "    train_ridge_rmse = rmse(Y_sample_train, train_ridge_pred)\n",
    "    print(\"For alpha=\",val)\n",
    "    print(\"RMSE on train = \", train_ridge_rmse)\n",
    "    \n",
    "    # Calculate RMSE for ridge Reg on test\n",
    "    test_ridge_pred = linreg_ridge.predict(X_sample_test)\n",
    "    test_ridge_rmse = rmse(Y_sample_test, test_ridge_pred)\n",
    "    print(\"RMSE on test = \", test_ridge_rmse)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression on sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha= 0.1\n",
      "RMSE on train =  1.752144934016974\n",
      "RMSE on test =  2.046303703436911\n",
      "\n",
      "For alpha= 0.5\n",
      "RMSE on train =  1.900195308184129\n",
      "RMSE on test =  2.1622796910597226\n",
      "\n",
      "For alpha= 2\n",
      "RMSE on train =  2.133262073126023\n",
      "RMSE on test =  2.2886987972529296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create list of different alpha values for lasso\n",
    "lasso_val = [0.1, 0.5, 2]\n",
    "\n",
    "for val in lasso_val:\n",
    "    # Fit using lasso\n",
    "    linreg_lasso = Lasso(alpha=val).fit(X_sample_train, Y_sample_train)\n",
    "    train_lasso_pred = linreg_lasso.predict(X_sample_train)\n",
    "    \n",
    "    # Calculate RMSE for lasso Reg on train\n",
    "    train_lasso_rmse = rmse(Y_sample_train, train_lasso_pred)\n",
    "    print(\"For alpha=\",val)\n",
    "    print(\"RMSE on train = \", train_lasso_rmse)\n",
    "    \n",
    "    # Calculate RMSE for lasso Reg on test\n",
    "    test_lasso_pred = linreg_lasso.predict(X_sample_test)\n",
    "    test_lasso_rmse = rmse(Y_sample_test, test_lasso_pred)\n",
    "    print(\"RMSE on test = \", test_lasso_rmse)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations on RMSE values after we overfit the model - In all three cases the test RMSE is higher than the train RMSE which is what we expected i.e the model will overfit the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample design matrix condition number 1797.3717702833685\n",
      "Sample train set condition number 1941.247032065037\n"
     ]
    }
   ],
   "source": [
    "# display condition numbers\n",
    "print(\"Sample design matrix condition number\", np.linalg.cond(X_sample))\n",
    "print(\"Sample train set condition number\", np.linalg.cond(X_sample_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition number of the sample training set is much higher than the condition numbers of all the other design matrixes so far."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
